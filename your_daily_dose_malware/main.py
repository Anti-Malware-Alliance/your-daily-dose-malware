import click
from commands.scraper import scraper
import requests
from dotenv import load_dotenv
import os
load_dotenv()
@click.command(
    help="""
    Download eitheir hundred recent malwares uploaded within the last 60 min or  all the recent malwares uploaded within the last 48 hours sha256 hash by using api from 'https://mb-api.abuse.ch/api/v1/' 

    -s256 or --by-sha256: get the lastest sha256 hashes from 'https://bazaar.abuse.ch/export/txt/sha256/recent' save them in sha256_names.txt then for each file  download all malwares in zip file

    -hr or --hundred-recent: get the lastest hundred recent malwares uploaded within the last 60 min
    """)
@click.option('-s256','--by-sha256',is_flag=True)
@click.option('-hr','--hundred-recent',is_flag=True)
def run_scrapper(by_sha256, hundred_recent):
    headers = {
        'API-KEY':os.getenv('API_KEY')
    }
    if hundred_recent:
        response = requests.post('https://mb-api.abuse.ch/api/v1/', data={'query':'get_recent','selector':'100'}, headers=headers)
        json_response = response.json()
        
        if json_response['query_status'] == 'no_selector':
            click.echo('	No selector provided. Please use either time or limit as selector',color=True)
        if json_response['query_status'] == 'unknown_selector':
            click.echo('	Selector unknown. Please use either time or limit as selector')
        if json_response['query_status'] == 'no_results':
            click.echo('	Your query yield no results')
        else:
            data_lenght = len(json_response['data'])
            click.echo(f'	Your query yield {data_lenght} results')
            for data in json_response['data']:
                sha256_name = data['sha256_hash']
                if os.path.exists(f'malware_{sha256_name[:4]}.zip'):
                    continue
                response = requests.post('https://mb-api.abuse.ch/api/v1/', data={'query':'get_file','sha256_hash':sha256_name}, headers=headers)
                with open(f'malware_{sha256_name[:4]}.zip', 'wb+') as f:
                    f.write(response.content)
                    click.echo(f'	malware_{sha256_name[:4]}.zip downloaded')
    elif by_sha256:
        response  = requests.post('https://bazaar.abuse.ch/export/txt/sha256/recent', headers=headers)
        with open('sha256_names.txt', 'wb+') as f:
            f.write(response.content)
            f.seek(0) # go back to the top of the file
            new_hashes = list()
            file_lines = [line.strip() for line in f.readlines()]
            for index, line in enumerate(file_lines,start=0):
                if index > 8 and index < len(file_lines)-1: # skip the first 9 lines and last line
                    click.echo(line)
                    new_hashes.append(line)
                continue
        with open('sha256_names.txt', 'w') as f:
            for line in new_hashes:
                f.write(line.decode('utf-8') + '\n')
        sha256_names = open('sha256_names.txt', 'r').readlines()
        click.echo(f'	{len(sha256_names)} hashes downloaded')
        for sha256_hash in sha256_names:
            if os.path.exists(f'malware_{sha256_hash[:4]}.zip'):
                continue
            response = requests.post('https://mb-api.abuse.ch/api/v1/', data={'query':'get_file','sha256_hash':sha256_hash}, headers=headers)
            with open(f'malware_{sha256_hash[:4]}.zip', 'wb') as f:
                f.write(response.content)
            click.echo(f'	malware_{sha256_hash[:4]}.zip downloaded')
    else:
        click.echo('	No selector provided. Please use either by_sha256, hundred_recent as selector',)

if __name__ == '__main__':
    scraper.add_command(run_scrapper)
    scraper()
